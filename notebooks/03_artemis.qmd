# Running AlphaFold on the Artemis HPC

<div class="questions">

## Questions

- How do I run AlphaFold on Artemis?
- How can I modify a template AlphaFold job?
</div>


# How do I run alphaFold on Artemis?

AlphaFold can be accessed by executing
```bash
module load alphafold
```

There are several (large) required genetic databases and parameters AlphaFold requires. Different versions of these are conviently available on Artemis in the common folder: `/project/data/alphafold2/` 
If there is additional databases you require, please fill in a [support ticket](https://sydneyuni.service-now.com/sm?id=sc_cat_item&sys_id=1ab0bb626d2935008dd31a4dcf150a21&sysparm_category=56db92a0db1f73042d38cae43a961918).


To actually run a computationally intensive AlphaFold job, we must create a PBS "jobscript", which is a standard shell script with a few PBS-specific directives, that is sent to the job scheduler for execution. 

## Make a PBS Jobscript

Make a new file called `alpha_job.pbs`.
The contents at a minimum, should look something like this.

```bash
#!/bin/bash

#PBS -P Training
#PBS -l select=1:ncpus=8:mem=32gb:ngpus=1
#PBS -l walltime=04:00:00
#PBS -N job01_gpu

# Load necessary modules (on Artemis, this will load the correct python environment with AlphaFold installed)
module load alphafold hmmer hh-suite kalign

# Navigate to your directory 
#cd /project/Training/ALPHAFOLD
cd $PBS_O_WORKDIR

# Set a working directory
export WORKDIR=`pwd`

# Set the alphafold base database directory
export ALPHADB=/project/data/alphafold2/20220323

# Run the AlphaFold2 prediction command. Note most database paths are required
run_alphafold.py \
        --data_dir=${ALPHADB} \
        --uniref90_database_path=${ALPHADB}/uniref90/uniref90.fasta \
        --mgnify_database_path=${ALPHADB}/mgnify/mgy_clusters_2018_12.fa \
        --template_mmcif_dir=${ALPHADB}/pdb_mmcif/mmcif_files/ \
        --obsolete_pdbs_path=${ALPHADB}/pdb_mmcif/obsolete.dat \
        --fasta_paths=/project/Training/DATA/input.fasta \
        --output_dir=${WORKDIR}/output_directory_gpu \
        --db_preset=full_dbs \
        --max_template_date=2022-03-23 \
        --use_gpu_relax=False \
        --model_preset=monomer \
        --pdb70_database_path=${ALPHADB}/pdb70/pdb70 \
        --bfd_database_path=${ALPHADB}/bfd/bfd_metaclust_clu_complete_id30_c90_final_seq.sorted_opt \
        --uniclust30_database_path=${ALPHADB}/uniclust30/uniclust30_2018_08/uniclust30_2018_08
```

Now we can submit the job to the queue
```bash
qsub alpha_job.pbs
```

This will execute when compute resources become availble. Check the status with: 

```bash
qstat -x -u <unikey>
```

You will see most requirments are on Artemis already, but you must bring your own `.fasta` file.




